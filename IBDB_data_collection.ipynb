{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51af9115",
   "metadata": {},
   "source": [
    "# IBDB Webscraping\n",
    "This file webscrapes publically available data from the Broadway League's IBDB (Internet Broadway Database) for the purposes of analyzing the importance of Tony Awards outcomes for Broadway Productions.\n",
    "\n",
    "This file borrows code in its first few chunks and takes general inspiration from the following [Colaboratory Jupyter Notebook](https://colab.research.google.com/drive/1IVwOhBMYay14NkO7kGkrPu0Ij9dSDdEP) by Yaakov Bressler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7d3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import string\n",
    "#import time\n",
    "#import json   #might not need commented out ones\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import ast\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ca4c1",
   "metadata": {},
   "source": [
    "## Scraping the names of the shows we are interested in\n",
    "\n",
    "### Create a function that grabs links from a page, using a tag to identify value of link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7043761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinks_tagged_fast(url, tag):\n",
    "    \"\"\"\n",
    "    This function finds elements (nodes) at a given url that have attribute 'href' and returns a list of all the \n",
    "    urls the href attributes refer to. \n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    html_doc = r.text\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    links = []\n",
    "    # set the opening of each link to be...\n",
    "    tag = tag\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(tag)}):\n",
    "        links.append(link.get('href'))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ea3dd",
   "metadata": {},
   "source": [
    "https://www.broadwayworld.com/browseshows.cfm?showtype=BR\n",
    "\n",
    "The above link is your starting point. It will allow us to get the name of every Broadway production that opened between 1979 and now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567180b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_links_year(year_url):\n",
    "    \"\"\"\n",
    "    This function webscrapes from a page on broadwayworld.com to get the urls to many webpages for different\n",
    "    Broadway shows. Each page is for a different show that has been on Broadway. This function scrapes the links for\n",
    "    every show that opened since 1979. It returns a list of the urls of interest.\n",
    "    \"\"\"\n",
    "    url = year_url\n",
    "    tag_year = 'browseshows.cfm?'\n",
    "    #calling previous function to get the link I want\n",
    "    years = getLinks_tagged_fast(url, tag_year)[1:]\n",
    "    page_base = 'https://www.broadwayworld.com/'\n",
    "    years_loop =[]\n",
    "    for year in years:\n",
    "        #focusing on 1979 or later\n",
    "        if year[-4:].isdigit() and int(year[-4:]) >= 1979:\n",
    "            years_loop.append(page_base+year)\n",
    "    \n",
    "    # Now you have all the years\n",
    "    tag_show = 'https://www.broadwayworld.com/shows/backstage.php?'\n",
    "    show_links_nested = []\n",
    "    for year in years_loop:\n",
    "        show_links_nested.append(getLinks_tagged_fast(year,tag_show))\n",
    "    show_links = sum(show_links_nested, [])\n",
    "    \n",
    "    return show_links\n",
    "    \n",
    "#running function to get my list of links to the productions I want\n",
    "year_url = 'https://www.broadwayworld.com/browseshows.cfm?showtype=BR'\n",
    "show_links = get_show_links_year(year_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f54d8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(show_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d123a",
   "metadata": {},
   "source": [
    "From here, we need to iterate through `show_links` to get the name of every show that has been on Broadway since 1979. This is important because we need to know which shows to search for on the IBDB (shows with productions from 1979 or later), and which shows to ignore (show that were pre-1979). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd398254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_name(url):\n",
    "    \"\"\"\n",
    "    This function takes a url for a given show as input and uses an xpath statment to search for the name of the\n",
    "    show on the website. It returns the name of the show. \n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    #make sure url actually exists\n",
    "    assert response.status_code == 200\n",
    "\n",
    "    show_html = response.text\n",
    "    htmlparser = etree.HTMLParser()\n",
    "    tree = etree.parse(io.StringIO(show_html), parser=htmlparser)\n",
    "    showroot = tree.getroot()\n",
    "    #this xml path is the same for every url, it will give you the name of the show for that url\n",
    "    show_name = showroot.xpath(\"//span[@itemprop = 'name']/text()\")[1]\n",
    "    \n",
    "    return show_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf19f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oliver!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the function on a random url (tried this with several urls)\n",
    "get_show_name('https://www.broadwayworld.com/shows/backstage.php?showid=6366')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efdc832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using get_show_name function to make a list of every single show I want to find data on\n",
    "#took about 10 minutes to run this chunk\n",
    "show_names = []\n",
    "for link in show_links:\n",
    "    show_name = get_show_name(link)\n",
    "    show_names.append(show_name)\n",
    "    \n",
    "len(show_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212990b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#due to the presence of revivals in the list, some show names appear more than once\n",
    "#therefore, to reduce redundancy when I search for these shows on the database, I am only keeping unique show names\n",
    "unique_show_names = []\n",
    "for show in show_names:\n",
    "    if show not in unique_show_names:\n",
    "        unique_show_names.append(show)    \n",
    "\n",
    "#print(unique_show_names)     \n",
    "len(unique_show_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f859198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database will not accept searches with & or + in them, so I must replace these with 'and'\n",
    "for i in range(len(unique_show_names)):\n",
    "    unique_show_names[i] = unique_show_names[i].replace('+', 'and')\n",
    "    unique_show_names[i] = unique_show_names[i].replace('&', 'and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a60780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_show_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140baae",
   "metadata": {},
   "source": [
    "## Searching for shows of interest on the IBDB\n",
    "TO DO: give overview of this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bda6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_alt_path(path):\n",
    "    \"\"\"\n",
    "    When the initial path for webscraping (in the next chunk) does not produce results, this function uses an\n",
    "    alternate path to find the urls that I want. There are two potential alternate paths that can yield results.\n",
    "    This function has no return value; it edits alt_url_list in place\n",
    "    \"\"\"\n",
    "    alt_web_elts = driver.find_elements('xpath', path)\n",
    "    assert len(alt_web_elts) > 0\n",
    "    alt_results = [elt.get_attribute(\"href\") for elt in alt_web_elts]\n",
    "    alt_urls_list.extend(alt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d7d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this chunk took about 1:30 hours to run\n",
    "#the xpath statement that will get me the href for each production I am interested in\n",
    "prod_xpath = '//div[@id = \"nyc-productions\" and @data-id = \"nyc-productions\"]/div/div/div/div/a'#/@href'\n",
    "#alt_path = f\"//div[@data-id = 'shows']/div[@class = 'row']/div/a[text() = {show}]\"\n",
    "\n",
    "#this will be a list all of the urls that I need \n",
    "urls_list = []\n",
    "#TO DO: explain this\n",
    "alt_urls_list = []\n",
    "#list of show name searches that did not produce needed results \n",
    "failed_searches = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "#test_shows = ['The King and I', 'Dear Evan Hansen', \"Rodgers and Hammerstein's Cinderella\",'Spring Awakening']\n",
    "#test_shows = [\"Is He Dead?\", 'Sweeney Todd','Awake and Sing!', 'Jerry Springer: The Opera']\n",
    "for show in unique_show_names:\n",
    "    driver.get('https://www.ibdb.com/shows/')     #website I am searching from (IBDB)\n",
    "    search_box = driver.find_element('name','ShowProperName')    #locating the searchbar\n",
    "    search_box.send_keys(show)       #automating the searches (will store results in a list later)\n",
    "    search_box.submit()\n",
    "    #search_box.send_keys(Keys.ENTER)  #other way to do above line of code\n",
    "    web_elts = driver.find_elements('xpath', prod_xpath)\n",
    "    try:\n",
    "        assert len(web_elts) > 0\n",
    "    except:\n",
    "        #alt_path is the first option for searches that do not immediately give us the desire results\n",
    "        try:\n",
    "            alt_path = f'//div[@data-id = \"shows\"]/div[@class = \"row\"]/div/a[text() = \"{show}\"]'\n",
    "            search_alt_path(alt_path)\n",
    "            #alt_web_elts = driver.find_elements('xpath', alt_path)\n",
    "            #assert len(alt_web_elts) > 0\n",
    "            #alt_results = [elt.get_attribute(\"href\") for elt in alt_web_elts]\n",
    "            #alt_urls_list.extend(alt_results)\n",
    "        except:\n",
    "            #second option for searches that do not immediately give desired results\n",
    "            try:\n",
    "                alt_path_2 = f'//p/a[text() = \"{show}\"]'\n",
    "                search_alt_path(alt_path_2)\n",
    "                #alt_web_elts = driver.find_elements('xpath', alt_path_2)\n",
    "                #print(alt_web_elts)\n",
    "                #assert len(alt_web_elts) > 0\n",
    "                #alt_results = [elt.get_attribute(\"href\") for elt in alt_web_elts]\n",
    "                #alt_urls_list.extend(alt_results)\n",
    "            except:\n",
    "                failed_searches.append(show)\n",
    "\n",
    "    #getting href I need from each selenium WebElement\n",
    "    results = [elt.get_attribute(\"href\") for elt in web_elts]\n",
    "    urls_list.extend(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2928c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alt_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7209fc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be153f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fail_path works, put this code under except\n",
    "#from here, put all unfail_results in a list\n",
    "#have separate chunk that iterates through them, grabs relevant info, and extends onto urls_list\n",
    "#driver = webdriver.Chrome()\n",
    "\n",
    "#example = 'Sweeney Todd'\n",
    "#fail_path = f\"//div[@data-id = 'shows']/div[@class = 'row']/div/a[text() = '{example}']\"\n",
    "#driver.get('https://www.ibdb.com/shows/')     #website I am searching from (IBDB)\n",
    "#search_box = driver.find_element('name','ShowProperName')    #locating the searchbar\n",
    "#search_box.send_keys(example)       #automating the searches (will store results in a list later)\n",
    "#search_box.submit()\n",
    "#fail_web_elts = driver.find_elements('xpath', fail_path)\n",
    "#unfail_results = [elt.get_attribute(\"href\") for elt in fail_web_elts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "619b01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unfail_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf08e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alt_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c9d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2105"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length is longer because several pre 1979 productions urls were scraped, these will be excluded by next big chunk\n",
    "len(urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb481cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can fix some of this by accounting for searches that result in \"Did you mean...\"\n",
    "#might not be necessary though\n",
    "len(failed_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cfecb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in alt_urls_list:\n",
    "    resp = requests.get(url)\n",
    "    prod_html = resp.text\n",
    "    soup = BeautifulSoup(prod_html, 'html.parser')\n",
    "    tree = etree.HTML(str(soup)) \n",
    "    prod_urls = tree.xpath(prod_xpath + '/@href')\n",
    "    prod_urls = ['https://www.ibdb.com' + elt for elt in prod_urls]\n",
    "    urls_list.extend(prod_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c13a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2897"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#once again: many of these urls are for pre 1979 productions. They will be filtered out in the next chunk\n",
    "len(urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e732cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#took about 2 hours to run this chunk\n",
    "#this LoD (poorly structured because of IBDB layout) will have weekly gross/capacity info\n",
    "prod_data_list = []\n",
    "\n",
    "#this LoD will have Tony nom/win info\n",
    "tony_data_LoD = []\n",
    "\n",
    "#this xpath give me the name of each award the production was nominated for\n",
    "noms_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div/div/div/h4/text()\"\n",
    "#this xpath will give me the number of awards the production won\n",
    "wins_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class='col s1 right-align']/img[@src = '/Images/award.png']\"\n",
    "#this xpath will give me the year that the production was eligible for awards\n",
    "#this path only works if the production received noms, for productions with 0 noms, I might have to manually put in the year\n",
    "year_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class = 'col s11']/div/div[@class = 'col s12' and position() = 2]/text()\"\n",
    "#this path gives me the opening date for a production, it is the path that will be used for productions with 0 noms\n",
    "alt_year_path = \"//div[@class = 'col s5 m3 l5 txt-paddings']/div[@class = 'xt-main-title']/text()\"\n",
    "#this xpath will give me the type of show the production was (musical, play, or special)\n",
    "type_path = \"//div[@class='row wrapper hide-on-med-and-up']/div[@class='col s12 txt-paddings tag-block-compact']/i[position() = 1]/text()\"\n",
    "\n",
    "for url in urls_list:\n",
    "    resp = requests.get(url)\n",
    "    prod_html = resp.text\n",
    "    soup = BeautifulSoup(prod_html, 'html.parser')\n",
    "    #finding node that has javascript text with our data\n",
    "    script = soup.find_all('script', type='text/javascript')[1]   #node at [1] is one with our data\n",
    "    #making script into a string so I can easily parse through it\n",
    "    js: str = script.text\n",
    "        \n",
    "    #need a 'try:' because the next few lines of code will not work for productions with no finanical data \n",
    "    #(i.e. pre 1979)\n",
    "    try:\n",
    "        #using a regex to search for the dict we are looking for (i.e. the one that has the data)\n",
    "        raw_json = re.search('var grossdata = {0:\\[.*\\] };', js, flags=re.MULTILINE).group(0)\n",
    "        #[16:-1] to exclude javascript syntax stuff\n",
    "        data = ast.literal_eval(raw_json[16:-1])\n",
    "        #adding key:value pair to dict to keep track of which production is which\n",
    "        data['production'] = url[41:]\n",
    "        prod_data_list.append(data)\n",
    "        \n",
    "        #scraping Tony info now\n",
    "        #We must do this within the try because this allows us to skip Tony info for productions with no financial data\n",
    "        #REACH GOAL: split awards into major/minor categories\n",
    "        # ^ Based on the layout of the website, it would be tedious/difficult to do this\n",
    "        tree = etree.HTML(str(soup)) \n",
    "        nominations = tree.xpath(noms_path)\n",
    "        num_noms = len(nominations)\n",
    "        num_wins = len(tree.xpath(wins_path))\n",
    "        try:\n",
    "            year = int(tree.xpath(year_path)[0][26:30])\n",
    "        except:\n",
    "            year = tree.xpath(alt_year_path)[0]\n",
    "        show_type = tree.xpath(type_path)[0]\n",
    "        prod_award_dict = {'production': url[41:], 'nominations': num_noms, 'wins': num_wins, 'type': show_type, 'year': year}\n",
    "        tony_data_LoD.append(prod_award_dict)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd66dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 4 2015 Musical\n"
     ]
    }
   ],
   "source": [
    "#testing new stuff\n",
    "#TO DO: delete this\n",
    "noms_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div/div/div/h4/text()\"\n",
    "wins_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class='col s1 right-align']/img[@src = '/Images/award.png']\"\n",
    "year_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class = 'col s11']/div/div[@class = 'col s12' and position() = 2]/text()\"\n",
    "type_path = \"//div[@class='row wrapper hide-on-med-and-up']/div[@class='col s12 txt-paddings tag-block-compact']/i[position() = 1]/text()\"\n",
    "\n",
    "test_url = 'https://www.ibdb.com/broadway-production/escape-to-margaritaville-515030'\n",
    "test_url = 'https://www.ibdb.com/broadway-production/the-king-and-i-497593'\n",
    "resp = requests.get(test_url)\n",
    "prod_html = resp.text\n",
    "soup = BeautifulSoup(prod_html, 'html.parser')\n",
    "tree = etree.HTML(str(soup)) \n",
    "nominations = tree.xpath(noms_path)\n",
    "num_noms = len(nominations)\n",
    "num_wins = len(tree.xpath(wins_path))\n",
    "try:\n",
    "    year = int(tree.xpath(year_path)[0][26:30])\n",
    "except:\n",
    "    year = tree.xpath(\"//div[@class = 'col s5 m3 l5 txt-paddings']/div[@class = 'xt-main-title']/text()\")[0]\n",
    "show_type = tree.xpath(type_path)[0]\n",
    "print(num_noms, num_wins, year, show_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c883d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'production': 'bad-cinderella-535361',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 'Mar 23, 2023'},\n",
       " {'production': 'dancin-4051',\n",
       "  'nominations': 7,\n",
       "  'wins': 2,\n",
       "  'type': 'Musical',\n",
       "  'year': 1978},\n",
       " {'production': 'dancin-535808',\n",
       "  'nominations': 1,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 2023},\n",
       " {'production': 'camelot-13313',\n",
       "  'nominations': 2,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 1981},\n",
       " {'production': 'camelot-4143',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 'Nov 15, 1981'},\n",
       " {'production': 'camelot-4571',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 'Jun 21, 1993'},\n",
       " {'production': 'camelot-534339',\n",
       "  'nominations': 5,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 2023},\n",
       " {'production': 'el-mago-pop-536773',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Special',\n",
       "  'year': 'Aug 20, 2023'},\n",
       " {'production': 'fat-ham-535958',\n",
       "  'nominations': 5,\n",
       "  'wins': 0,\n",
       "  'type': 'Play',\n",
       "  'year': 2023},\n",
       " {'production': 'good-night-oscar-535325',\n",
       "  'nominations': 3,\n",
       "  'wins': 1,\n",
       "  'type': 'Play',\n",
       "  'year': 2023}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tony_data_LoD[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcad0ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Feb 19, 2023',\n",
       "  '$318,478',\n",
       "  '-2147483648%',\n",
       "  '2,796',\n",
       "  '100%',\n",
       "  'Feb 19',\n",
       "  318478.0,\n",
       "  0.0,\n",
       "  2796.0,\n",
       "  2796.0,\n",
       "  '2',\n",
       "  '0'],\n",
       " ['Feb 26, 2023',\n",
       "  '$684,822',\n",
       "  '-2147483648%',\n",
       "  '9,107',\n",
       "  '93%',\n",
       "  'Feb 26',\n",
       "  684822.0,\n",
       "  0.0,\n",
       "  9107.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 5, 2023',\n",
       "  '$568,165',\n",
       "  '-2147483648%',\n",
       "  '8,695',\n",
       "  '89%',\n",
       "  'Mar 5',\n",
       "  568165.0,\n",
       "  0.0,\n",
       "  8695.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 12, 2023',\n",
       "  '$592,938',\n",
       "  '-2147483648%',\n",
       "  '8,663',\n",
       "  '89%',\n",
       "  'Mar 12',\n",
       "  592938.0,\n",
       "  0.0,\n",
       "  8663.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 19, 2023',\n",
       "  '$642,196',\n",
       "  '-2147483648%',\n",
       "  '8,752',\n",
       "  '89%',\n",
       "  'Mar 19',\n",
       "  642196.0,\n",
       "  0.0,\n",
       "  8752.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 26, 2023',\n",
       "  '$633,929',\n",
       "  '-2147483648%',\n",
       "  '10,185',\n",
       "  '91%',\n",
       "  'Mar 26',\n",
       "  633929.0,\n",
       "  0.0,\n",
       "  10185.0,\n",
       "  11184.0,\n",
       "  '3',\n",
       "  '5'],\n",
       " ['Apr 2, 2023',\n",
       "  '$631,890',\n",
       "  '-2147483648%',\n",
       "  '8,978',\n",
       "  '80%',\n",
       "  'Apr 2',\n",
       "  631890.0,\n",
       "  0.0,\n",
       "  8978.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 9, 2023',\n",
       "  '$639,391',\n",
       "  '-2147483648%',\n",
       "  '9,459',\n",
       "  '85%',\n",
       "  'Apr 9',\n",
       "  639391.0,\n",
       "  0.0,\n",
       "  9459.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 16, 2023',\n",
       "  '$571,192',\n",
       "  '-2147483648%',\n",
       "  '8,069',\n",
       "  '72%',\n",
       "  'Apr 16',\n",
       "  571192.0,\n",
       "  0.0,\n",
       "  8069.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 23, 2023',\n",
       "  '$539,119',\n",
       "  '-2147483648%',\n",
       "  '7,280',\n",
       "  '65%',\n",
       "  'Apr 23',\n",
       "  539119.0,\n",
       "  0.0,\n",
       "  7280.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 30, 2023',\n",
       "  '$514,980',\n",
       "  '-2147483648%',\n",
       "  '7,281',\n",
       "  '65%',\n",
       "  'Apr 30',\n",
       "  514980.0,\n",
       "  0.0,\n",
       "  7281.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['May 7, 2023',\n",
       "  '$326,303',\n",
       "  '-2147483648%',\n",
       "  '6,006',\n",
       "  '54%',\n",
       "  'May 7',\n",
       "  326303.0,\n",
       "  0.0,\n",
       "  6006.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['May 14, 2023',\n",
       "  '$324,003',\n",
       "  '-2147483648%',\n",
       "  '7,068',\n",
       "  '63%',\n",
       "  'May 14',\n",
       "  324003.0,\n",
       "  0.0,\n",
       "  7068.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['May 21, 2023',\n",
       "  '$384,528',\n",
       "  '-2147483648%',\n",
       "  '7,647',\n",
       "  '68%',\n",
       "  'May 21',\n",
       "  384528.0,\n",
       "  0.0,\n",
       "  7647.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_data_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b381974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'production': 'bad-cinderella-535361',\n",
       "  'date': 'May 28, 2023',\n",
       "  'capacity': 69,\n",
       "  'gross': 351163.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Jun 4, 2023',\n",
       "  'capacity': 77,\n",
       "  'gross': 384017.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Feb 19, 2023',\n",
       "  'capacity': 100,\n",
       "  'gross': 318478.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Feb 26, 2023',\n",
       "  'capacity': 93,\n",
       "  'gross': 684822.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Mar 5, 2023',\n",
       "  'capacity': 89,\n",
       "  'gross': 568165.0}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO: Make these comments (and others) into markdown chunks\n",
    "#structure of prod_data_list (it is a poorly structured LoD):\n",
    "#each dict is one production\n",
    "#each key represent one season of data, with the exception of the key I added to represent the production\n",
    "#the value for each season key is an LoL \n",
    "#each list in the LoL represents one week of data for that production\n",
    "#in each list, we care about the vals at indeces: 0 (date of week), 4 (weekly capacity), 6 (weekly gross) \n",
    "\n",
    "#end result should be LoD of the following structure:\n",
    "#[{'production': 'the-king-and-i-497593', 'date': 'May 29, 2016', 'capacity':'76%', 'gross': 546476.0},...]\n",
    "\n",
    "prod_LoD = []\n",
    "#prod_data_list[2][0][0]\n",
    "for prod in prod_data_list:\n",
    "    for season in prod:\n",
    "        for week in prod[season]:\n",
    "            if type(week) == list:\n",
    "                #print(week)\n",
    "                relevant_data = {'production': prod['production'], 'date': week[0], 'capacity': int(week[4][:-1]), 'gross': week[6]}\n",
    "                prod_LoD.append(relevant_data)\n",
    "\n",
    "#see what first few rows of data look like\n",
    "prod_LoD[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72228e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: DELETE THIS CHUNK\n",
    "\n",
    "#this xpath give me the name of each award the production was nominated for\n",
    "#noms_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div/div/div/h4/text()\"\n",
    "#this xpath will give me the number of awards the production won\n",
    "#wins_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class='col s1 right-align']/img[@src = '/Images/award.png']\"\n",
    "#tony_data_list = []\n",
    "#type_list =[]\n",
    "#for url in urls_list[0:20]:\n",
    "#test = 'https://www.ibdb.com/broadway-production/the-king-and-i-497593'\n",
    "#test = 'https://www.ibdb.com/broadway-production/good-night-oscar-535325'\n",
    "    #resp = requests.get(url)\n",
    "    #prod_html = resp.text\n",
    "    #soup = BeautifulSoup(prod_html, 'html.parser')\n",
    "    #tree = etree.HTML(str(soup)) \n",
    "#year = tree.xpath(\"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class = 'col s11']/div/div[@class = 'col s12' and position() = 2]/text()\")[0]\n",
    "    #show_type = tree.xpath('//div[@class=\"row wrapper hide-on-med-and-up\"]/div[@class=\"col s12 txt-paddings tag-block-compact\"]/i[position() = 1]/text()')[0]\n",
    "    #type_list.append(show_type)\n",
    "#nominations = tree.xpath(noms_path)\n",
    "#num_noms = len(nominations)\n",
    "#num_wins = len(tree.xpath(wins_path))\n",
    "#prod_award_dict = {\"production\": url[41:], \"nominations\": num_noms, \"wins\": num_wins}\n",
    "#tony_data_list.append(prod_award_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "666dc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tony_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fdfdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nominations)\n",
    "#num_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362aa2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominations</th>\n",
       "      <th>wins</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad-cinderella-535361</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Mar 23, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancin-4051</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Musical</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancin-535808</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camelot-13313</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camelot-4143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Nov 15, 1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a-life-522289</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barnum-3949</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Musical</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home-3953</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuts-3948</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bent-3823</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nominations  wins     type          year\n",
       "production                                                     \n",
       "bad-cinderella-535361            0     0  Musical  Mar 23, 2023\n",
       "dancin-4051                      7     2  Musical          1978\n",
       "dancin-535808                    1     0  Musical          2023\n",
       "camelot-13313                    2     0  Musical          1981\n",
       "camelot-4143                     0     0  Musical  Nov 15, 1981\n",
       "...                            ...   ...      ...           ...\n",
       "a-life-522289                    3     0     Play          2020\n",
       "barnum-3949                     10     3  Musical          1980\n",
       "home-3953                        2     0     Play          1980\n",
       "nuts-3948                        1     0     Play          1980\n",
       "bent-3823                        2     0     Play          1980\n",
       "\n",
       "[1552 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tony_data = pd.DataFrame(tony_data_LoD)\n",
    "tony_data = tony_data.set_index('production')\n",
    "tony_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cceb1397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>capacity</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bad-cinderella-535361</th>\n",
       "      <th>May 28, 2023</th>\n",
       "      <td>69</td>\n",
       "      <td>351163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 4, 2023</th>\n",
       "      <td>77</td>\n",
       "      <td>384017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb 19, 2023</th>\n",
       "      <td>100</td>\n",
       "      <td>318478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb 26, 2023</th>\n",
       "      <td>93</td>\n",
       "      <td>684822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar 5, 2023</th>\n",
       "      <td>89</td>\n",
       "      <td>568165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuts-3948</th>\n",
       "      <th>Jul 20, 1980</th>\n",
       "      <td>63</td>\n",
       "      <td>46596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bent-3823</th>\n",
       "      <th>Jun 8, 1980</th>\n",
       "      <td>36</td>\n",
       "      <td>43510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 15, 1980</th>\n",
       "      <td>51</td>\n",
       "      <td>57117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 22, 1980</th>\n",
       "      <td>48</td>\n",
       "      <td>52885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 29, 1980</th>\n",
       "      <td>57</td>\n",
       "      <td>63754.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    capacity     gross\n",
       "production            date                            \n",
       "bad-cinderella-535361 May 28, 2023        69  351163.0\n",
       "                      Jun 4, 2023         77  384017.0\n",
       "                      Feb 19, 2023       100  318478.0\n",
       "                      Feb 26, 2023        93  684822.0\n",
       "                      Mar 5, 2023         89  568165.0\n",
       "...                                      ...       ...\n",
       "nuts-3948             Jul 20, 1980        63   46596.0\n",
       "bent-3823             Jun 8, 1980         36   43510.0\n",
       "                      Jun 15, 1980        51   57117.0\n",
       "                      Jun 22, 1980        48   52885.0\n",
       "                      Jun 29, 1980        57   63754.0\n",
       "\n",
       "[55318 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data = pd.DataFrame(prod_LoD)\n",
    "weekly_data = weekly_data.set_index(['production','date'])\n",
    "weekly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a519d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to data folder\n",
    "tony_data.to_csv('data/tony_data.csv')\n",
    "weekly_data.to_csv('data/weekly_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
