{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51af9115",
   "metadata": {},
   "source": [
    "# IBDB Webscraping\n",
    "This file webscrapes publically available data from the Broadway League's [IBDB](https://www.ibdb.com/shows) (Internet Broadway Database) for the purposes of analyzing the impact of Tony Awards outcomes on Broadway Productions.\n",
    "\n",
    "This file borrows code in its first few chunks and takes general inspiration from the following [Colaboratory Jupyter Notebook](https://colab.research.google.com/drive/1IVwOhBMYay14NkO7kGkrPu0Ij9dSDdEP) by Yaakov Bressler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7d3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import string\n",
    "#import json\n",
    "#import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import ast\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ca4c1",
   "metadata": {},
   "source": [
    "## Scraping the names of the shows we are interested in\n",
    "\n",
    "We need to create a list of all productions that opened on Broadway between 1979 - 2023, so that we can search for them on the IBDB. To that end, this portion of the notebook, scrapes the names of these productions from a page on [broadwayworld.com](https://www.broadwayworld.com/browseshows.cfm?showtype=BR)\n",
    "\n",
    "### Create a function that grabs links from a page, using a tag to identify value of link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7043761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinks_tagged_fast(url, tag):\n",
    "    \"\"\"\n",
    "    This function finds elements (nodes) at a given url that have attribute 'href' and returns a list of all the \n",
    "    urls the href attributes refer to. \n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    html_doc = r.text\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    links = []\n",
    "    # set the opening of each link to be...\n",
    "    tag = tag\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(tag)}):\n",
    "        links.append(link.get('href'))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ea3dd",
   "metadata": {},
   "source": [
    "https://www.broadwayworld.com/browseshows.cfm?showtype=BR\n",
    "\n",
    "The above link is our starting point. It will allow us to get the name of every Broadway production that opened between 1979 and now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567180b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_links_year(year_url):\n",
    "    \"\"\"\n",
    "    This function webscrapes from a page on broadwayworld.com to get the urls to many webpages for different\n",
    "    Broadway shows. Each page is for a different show that has been on Broadway. This function scrapes the links for\n",
    "    every show that opened since 1979. It returns a list of the urls of interest.\n",
    "    \"\"\"\n",
    "    url = year_url\n",
    "    tag_year = 'browseshows.cfm?'\n",
    "    #calling previous function to get the links I want for the different years\n",
    "    years = getLinks_tagged_fast(url, tag_year)[1:]\n",
    "    page_base = 'https://www.broadwayworld.com/'\n",
    "    years_loop =[]\n",
    "    for year in years:\n",
    "        #focusing on 1979 or later\n",
    "        if year[-4:].isdigit() and int(year[-4:]) >= 1979:\n",
    "            years_loop.append(page_base+year)\n",
    "    \n",
    "    # Now you have all the years\n",
    "    tag_show = 'https://www.broadwayworld.com/shows/backstage.php?'\n",
    "    show_links_nested = []\n",
    "    for year in years_loop:\n",
    "        show_links_nested.append(getLinks_tagged_fast(year,tag_show))\n",
    "    show_links = sum(show_links_nested, [])\n",
    "    \n",
    "    return show_links\n",
    "    \n",
    "#running function to get my list of links to the productions I want\n",
    "year_url = 'https://www.broadwayworld.com/browseshows.cfm?showtype=BR'\n",
    "show_links = get_show_links_year(year_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f54d8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(show_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d123a",
   "metadata": {},
   "source": [
    "The above number is the number of different productions that have opened between 1979 and now.\n",
    "\n",
    "From here, we need to iterate through `show_links` to get the name of every show that has been on Broadway since 1979. Once we have these names, we can search for them on the IBDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd398254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_name(url):\n",
    "    \"\"\"\n",
    "    This function takes a url for a given show's page on broadwayworld.com as input and uses an xpath statement to \n",
    "    search for the name of the show on the website. It returns the name of the show. \n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    #make sure url actually exists\n",
    "    assert response.status_code == 200\n",
    "\n",
    "    show_html = response.text\n",
    "    htmlparser = etree.HTMLParser()\n",
    "    tree = etree.parse(io.StringIO(show_html), parser=htmlparser)\n",
    "    showroot = tree.getroot()\n",
    "    #this xml path is the same for every url, it will give you the name of the show for that url\n",
    "    show_name = showroot.xpath(\"//span[@itemprop = 'name']/text()\")[1]\n",
    "    \n",
    "    return show_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf19f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oliver!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the function on a random url (tried this with several urls)\n",
    "get_show_name('https://www.broadwayworld.com/shows/backstage.php?showid=6366')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efdc832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using get_show_name function to make a list of every single show I want to find data on\n",
    "#took about 10 minutes to run this chunk\n",
    "show_names = []\n",
    "for link in show_links:\n",
    "    show_name = get_show_name(link)\n",
    "    show_names.append(show_name)\n",
    "    \n",
    "#should match length of show_links\n",
    "len(show_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016de4f4",
   "metadata": {},
   "source": [
    "Due to the presence of revivals in the list, some show names appear more than once. To reduce redundancy in our searches, we want to only keep unique show names. This will make the search process more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212990b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_show_names = []\n",
    "for show in show_names:\n",
    "    if show not in unique_show_names:\n",
    "        unique_show_names.append(show)    \n",
    "\n",
    "#print(unique_show_names)     \n",
    "len(unique_show_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f859198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database will not accept searches with & or + in them, so I must replace these with 'and'\n",
    "for i in range(len(unique_show_names)):\n",
    "    unique_show_names[i] = unique_show_names[i].replace('+', 'and')\n",
    "    unique_show_names[i] = unique_show_names[i].replace('&', 'and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a60780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_show_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140baae",
   "metadata": {},
   "source": [
    "## Searching for shows of interest on the IBDB\n",
    "\n",
    "The next step to is search the [IBDB](https://www.ibdb.com/shows) for the relevant productions. It would take us way too long to do these searches manually, so we need to automate the process using the selenium package. The next several chunks perform these searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bda6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_alt_path(path):\n",
    "    \"\"\"\n",
    "    When the initial path for webscraping (in the next chunk) does not produce results, this function uses an\n",
    "    alternate path to find the urls that we want. There are two potential alternate paths that can yield results.\n",
    "    This function has no return value; it edits alt_urls_list in place\n",
    "    \"\"\"\n",
    "    alt_web_elts = driver.find_elements('xpath', path)\n",
    "    assert len(alt_web_elts) > 0\n",
    "    alt_results = [elt.get_attribute(\"href\") for elt in alt_web_elts]\n",
    "    alt_urls_list.extend(alt_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a654dc0",
   "metadata": {},
   "source": [
    "In the next chunk, there is a list called `alt_urls_list`. We need this list because not all searches yield the same kind of results page. Most of the time, the search will take you directly to the page for the show you are looking for. However, if there are multiple shows with the same name, you are taken to a page that presents you with links to the different shows, and you need to pick the one you want. For example, when you search for \"Hamilton,\" you are given two results: the hit musical that opened in 2015, and an obscure play of the same name from 1917. You will get similar results if the name of the show you are searching for is contained in the names of other shows. For example, if you search for the play \"Wit,\" you get a very large number of results, most of which have the word \"with\" somewhere in the title. You can also get undesirable results if the website perceives a spelling error in your search. When this happens, you are taken to a page that says \"Did you mean:\" and then lists several shows, and usually one of them is the one you are looking for. We need to account for these alternate search results, or else we will miss several productions in the scraping process. Hence, we need a list that contains alternate results, so we can sift through them and get what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d7d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this chunk took about 1:30 hours to run\n",
    "\n",
    "#the xpath statement that will get us the href for most of the productions we am interested in\n",
    "prod_xpath = '//div[@id = \"nyc-productions\" and @data-id = \"nyc-productions\"]/div/div/div/div/a'#/@href'\n",
    "#alt_path = f\"//div[@data-id = 'shows']/div[@class = 'row']/div/a[text() = {show}]\"\n",
    "\n",
    "#this will be a list all of the urls that we need \n",
    "urls_list = []\n",
    "\n",
    "#not all searches yield the same kind of results page \n",
    "alt_urls_list = []\n",
    "\n",
    "#list of show name searches that failed to produce results \n",
    "failed_searches = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "#test_shows = ['The King and I', 'Dear Evan Hansen', \"Rodgers and Hammerstein's Cinderella\",'Spring Awakening']\n",
    "#test_shows = [\"Is He Dead?\", 'Sweeney Todd','Awake and Sing!', 'Jerry Springer: The Opera']\n",
    "for show in unique_show_names:\n",
    "    driver.get('https://www.ibdb.com/shows/')     #website we are searching from (IBDB)\n",
    "    search_box = driver.find_element('name','ShowProperName')    #locating the searchbar\n",
    "    search_box.send_keys(show)       #automating the searches (will store results in a list)\n",
    "    search_box.submit()\n",
    "    #search_box.send_keys(Keys.ENTER)  #other way to do above line of code\n",
    "    web_elts = driver.find_elements('xpath', prod_xpath)\n",
    "    try:\n",
    "        #if the initial xpath statement gives us no results, we need to try the alternate paths\n",
    "        assert len(web_elts) > 0\n",
    "    except:\n",
    "        #alt_path is the first option for searches that do not immediately give us the desired results\n",
    "        try:\n",
    "            alt_path = f'//div[@data-id = \"shows\"]/div[@class = \"row\"]/div/a[text() = \"{show}\"]'\n",
    "            search_alt_path(alt_path)\n",
    "        except:\n",
    "            #second option for searches that do not immediately give desired results\n",
    "            try:\n",
    "                alt_path_2 = f'//p/a[text() = \"{show}\"]'\n",
    "                search_alt_path(alt_path_2)\n",
    "            except:\n",
    "                #if the search still produces no results, we append the show to the failed searches list\n",
    "                failed_searches.append(show)\n",
    "\n",
    "    #getting href I need from each selenium WebElement\n",
    "    results = [elt.get_attribute(\"href\") for elt in web_elts]\n",
    "    urls_list.extend(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2928c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alt_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7209fc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c9d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2105"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf77f9e",
   "metadata": {},
   "source": [
    "The length of urls_list is longer than you might expect because the searches scraped several productions that were pre-1979, even though we made a point excluding these shows when building our list of shows to search for. This happened because some of the shows we search for that had productions in 1979 or later also had productions that opened before 1979. For example, \"The King and I\" was in our search list because there have been 3 productions of it since 1979. However, there were also two productions prior to 1979, both of which were included in url list. This unwanted productions will be filtered out once we start scraping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb481cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the number of shows we could not get results for\n",
    "#it was much higher before I accounted for alternate paths\n",
    "len(failed_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cfecb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the desired urls from alt_urls_list\n",
    "for url in alt_urls_list:\n",
    "    resp = requests.get(url)\n",
    "    prod_html = resp.text\n",
    "    soup = BeautifulSoup(prod_html, 'html.parser')\n",
    "    tree = etree.HTML(str(soup)) \n",
    "    prod_urls = tree.xpath(prod_xpath + '/@href')\n",
    "    prod_urls = ['https://www.ibdb.com' + elt for elt in prod_urls]\n",
    "    urls_list.extend(prod_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c13a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2897"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#once again: many of these urls are for pre 1979 productions. They will be filtered out in the next chunk\n",
    "len(urls_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ea2dc",
   "metadata": {},
   "source": [
    "## Scraping weekly data and tony data\n",
    "\n",
    "This is the fun part! Now that we have the urls for every production we need (and some we don't need), we can scrape the data directly from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e732cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#took about 2 hours to run this chunk\n",
    "#this LoD (poorly structured because of IBDB layout) will have weekly gross/capacity info\n",
    "prod_data_list = []\n",
    "\n",
    "#this LoD will have Tony nom/win info, as well as whether a production was a play, musical, or special\n",
    "tony_data_LoD = []\n",
    "\n",
    "#this xpath gives us the name of each award the production was nominated for\n",
    "noms_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div/div/div/h4/text()\"\n",
    "\n",
    "#this xpath gives us the number of awards the production won\n",
    "wins_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class='col s1 right-align']/img[@src = '/Images/award.png']\"\n",
    "\n",
    "#this xpath gives us the year that the production was eligible for awards\n",
    "#this path only works if the production received noms \n",
    "#for productions with 0 noms, we will have to do something else \n",
    "year_path = \"//div[@class = 'collapsible-body awards-tab']/div[position() = 1]/div[@class = 'col s11']/div/div[@class = 'col s12' and position() = 2]/text()\"\n",
    "\n",
    "#this path gives me the opening date for a production\n",
    "#it is the path that will be used for productions with 0 noms\n",
    "alt_year_path = \"//div[@class = 'col s5 m3 l5 txt-paddings']/div[@class = 'xt-main-title']/text()\"\n",
    "\n",
    "#this xpath will give me the type of show the production was (musical, play, or special)\n",
    "type_path = \"//div[@class='row wrapper hide-on-med-and-up']/div[@class='col s12 txt-paddings tag-block-compact']/i[position() = 1]/text()\"\n",
    "\n",
    "for url in urls_list:\n",
    "    resp = requests.get(url)\n",
    "    prod_html = resp.text\n",
    "    soup = BeautifulSoup(prod_html, 'html.parser')\n",
    "    #finding node that has javascript text with our data\n",
    "    script = soup.find_all('script', type='text/javascript')[1]   #node at [1] is one with our data\n",
    "    #making script into a string so we can easily parse through it\n",
    "    js: str = script.text\n",
    "        \n",
    "    #need a 'try:' because the next few lines of code will not work for productions with no finanical data \n",
    "    #(i.e. pre 1979)\n",
    "    #this is good because we do not care about productions with no financial data\n",
    "    try:\n",
    "        #using a regex to search for the dict we are looking for (i.e. the one that has the weekly data)\n",
    "        raw_json = re.search('var grossdata = {0:\\[.*\\] };', js, flags=re.MULTILINE).group(0)\n",
    "        #[16:-1] to exclude unwanted javascript syntax\n",
    "        data = ast.literal_eval(raw_json[16:-1])\n",
    "        #adding key:value pair to dict to keep track of which production is which\n",
    "        data['production'] = url[41:]\n",
    "        prod_data_list.append(data)\n",
    "        \n",
    "        #scraping Tony info now\n",
    "        #We must do this within the try because this allows us to skip Tony info for productions with no financial data\n",
    "        # ^ thus making the code more efficient\n",
    "        #REACH GOAL: split awards into major/minor categories\n",
    "        # ^ Based on the layout of the website, it would be very tedious/difficult to do this\n",
    "        tree = etree.HTML(str(soup)) \n",
    "        nominations = tree.xpath(noms_path)\n",
    "        num_noms = len(nominations)\n",
    "        num_wins = len(tree.xpath(wins_path))\n",
    "        try:\n",
    "            year = int(tree.xpath(year_path)[0][26:30])\n",
    "        except:\n",
    "            year = tree.xpath(alt_year_path)[0]\n",
    "        show_type = tree.xpath(type_path)[0]\n",
    "        \n",
    "        #making well-formatted LoD with all of the Tony info\n",
    "        prod_award_dict = {'production': url[41:], 'nominations': num_noms, 'wins': num_wins, 'type': show_type, 'year': year}\n",
    "        tony_data_LoD.append(prod_award_dict)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c883d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'production': 'bad-cinderella-535361',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 'Mar 23, 2023'},\n",
       " {'production': 'dancin-4051',\n",
       "  'nominations': 7,\n",
       "  'wins': 2,\n",
       "  'type': 'Musical',\n",
       "  'year': 1978},\n",
       " {'production': 'dancin-535808',\n",
       "  'nominations': 1,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 2023},\n",
       " {'production': 'camelot-13313',\n",
       "  'nominations': 2,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 1981},\n",
       " {'production': 'camelot-4143',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 'Nov 15, 1981'},\n",
       " {'production': 'camelot-4571',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 'Jun 21, 1993'},\n",
       " {'production': 'camelot-534339',\n",
       "  'nominations': 5,\n",
       "  'wins': 0,\n",
       "  'type': 'Musical',\n",
       "  'year': 2023},\n",
       " {'production': 'el-mago-pop-536773',\n",
       "  'nominations': 0,\n",
       "  'wins': 0,\n",
       "  'type': 'Special',\n",
       "  'year': 'Aug 20, 2023'},\n",
       " {'production': 'fat-ham-535958',\n",
       "  'nominations': 5,\n",
       "  'wins': 0,\n",
       "  'type': 'Play',\n",
       "  'year': 2023},\n",
       " {'production': 'good-night-oscar-535325',\n",
       "  'nominations': 3,\n",
       "  'wins': 1,\n",
       "  'type': 'Play',\n",
       "  'year': 2023}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tony_data_LoD[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcad0ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Feb 19, 2023',\n",
       "  '$318,478',\n",
       "  '-2147483648%',\n",
       "  '2,796',\n",
       "  '100%',\n",
       "  'Feb 19',\n",
       "  318478.0,\n",
       "  0.0,\n",
       "  2796.0,\n",
       "  2796.0,\n",
       "  '2',\n",
       "  '0'],\n",
       " ['Feb 26, 2023',\n",
       "  '$684,822',\n",
       "  '-2147483648%',\n",
       "  '9,107',\n",
       "  '93%',\n",
       "  'Feb 26',\n",
       "  684822.0,\n",
       "  0.0,\n",
       "  9107.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 5, 2023',\n",
       "  '$568,165',\n",
       "  '-2147483648%',\n",
       "  '8,695',\n",
       "  '89%',\n",
       "  'Mar 5',\n",
       "  568165.0,\n",
       "  0.0,\n",
       "  8695.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 12, 2023',\n",
       "  '$592,938',\n",
       "  '-2147483648%',\n",
       "  '8,663',\n",
       "  '89%',\n",
       "  'Mar 12',\n",
       "  592938.0,\n",
       "  0.0,\n",
       "  8663.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 19, 2023',\n",
       "  '$642,196',\n",
       "  '-2147483648%',\n",
       "  '8,752',\n",
       "  '89%',\n",
       "  'Mar 19',\n",
       "  642196.0,\n",
       "  0.0,\n",
       "  8752.0,\n",
       "  9786.0,\n",
       "  '7',\n",
       "  '0'],\n",
       " ['Mar 26, 2023',\n",
       "  '$633,929',\n",
       "  '-2147483648%',\n",
       "  '10,185',\n",
       "  '91%',\n",
       "  'Mar 26',\n",
       "  633929.0,\n",
       "  0.0,\n",
       "  10185.0,\n",
       "  11184.0,\n",
       "  '3',\n",
       "  '5'],\n",
       " ['Apr 2, 2023',\n",
       "  '$631,890',\n",
       "  '-2147483648%',\n",
       "  '8,978',\n",
       "  '80%',\n",
       "  'Apr 2',\n",
       "  631890.0,\n",
       "  0.0,\n",
       "  8978.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 9, 2023',\n",
       "  '$639,391',\n",
       "  '-2147483648%',\n",
       "  '9,459',\n",
       "  '85%',\n",
       "  'Apr 9',\n",
       "  639391.0,\n",
       "  0.0,\n",
       "  9459.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 16, 2023',\n",
       "  '$571,192',\n",
       "  '-2147483648%',\n",
       "  '8,069',\n",
       "  '72%',\n",
       "  'Apr 16',\n",
       "  571192.0,\n",
       "  0.0,\n",
       "  8069.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 23, 2023',\n",
       "  '$539,119',\n",
       "  '-2147483648%',\n",
       "  '7,280',\n",
       "  '65%',\n",
       "  'Apr 23',\n",
       "  539119.0,\n",
       "  0.0,\n",
       "  7280.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['Apr 30, 2023',\n",
       "  '$514,980',\n",
       "  '-2147483648%',\n",
       "  '7,281',\n",
       "  '65%',\n",
       "  'Apr 30',\n",
       "  514980.0,\n",
       "  0.0,\n",
       "  7281.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['May 7, 2023',\n",
       "  '$326,303',\n",
       "  '-2147483648%',\n",
       "  '6,006',\n",
       "  '54%',\n",
       "  'May 7',\n",
       "  326303.0,\n",
       "  0.0,\n",
       "  6006.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['May 14, 2023',\n",
       "  '$324,003',\n",
       "  '-2147483648%',\n",
       "  '7,068',\n",
       "  '63%',\n",
       "  'May 14',\n",
       "  324003.0,\n",
       "  0.0,\n",
       "  7068.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8'],\n",
       " ['May 21, 2023',\n",
       "  '$384,528',\n",
       "  '-2147483648%',\n",
       "  '7,647',\n",
       "  '68%',\n",
       "  'May 21',\n",
       "  384528.0,\n",
       "  0.0,\n",
       "  7647.0,\n",
       "  11184.0,\n",
       "  '0',\n",
       "  '8']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_data_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91185055",
   "metadata": {},
   "source": [
    "`prod_data_list` is poorly structured and needs to be rearranged before we can convert it into a pandas dataframe. It is currently structured as follows:\n",
    "- each dictionary in the list represents one production\n",
    "- each key represents one season of data, with the excpetion of the key we added to represent the production\n",
    "- the value for each season key is an LoL\n",
    "- each list in the LoL represents one week of data for that production\n",
    "- in each of these weekly lists, we care about the values at indeces 0 (date), 4 (weekly capacity), and 6 (weekly gross)\n",
    "\n",
    "We want to create an LoD in which each dictionary represents one row (week) of data. For example, one row of data in the LoD shoul look like this:\n",
    "\n",
    "`[{'production': 'the-king-and-i-497593', 'date': 'May 29, 2016', 'capacity':'76%', 'gross': 546476.0},...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b381974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'production': 'bad-cinderella-535361',\n",
       "  'date': 'May 28, 2023',\n",
       "  'capacity': 69,\n",
       "  'gross': 351163.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Jun 4, 2023',\n",
       "  'capacity': 77,\n",
       "  'gross': 384017.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Feb 19, 2023',\n",
       "  'capacity': 100,\n",
       "  'gross': 318478.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Feb 26, 2023',\n",
       "  'capacity': 93,\n",
       "  'gross': 684822.0},\n",
       " {'production': 'bad-cinderella-535361',\n",
       "  'date': 'Mar 5, 2023',\n",
       "  'capacity': 89,\n",
       "  'gross': 568165.0}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the desired LoD\n",
    "prod_LoD = []\n",
    "#prod_data_list[2][0][0]\n",
    "for prod in prod_data_list:\n",
    "    for season in prod:\n",
    "        for week in prod[season]:\n",
    "            if type(week) == list:\n",
    "                #print(week)\n",
    "                relevant_data = {'production': prod['production'], 'date': week[0], 'capacity': int(week[4][:-1]), 'gross': week[6]}\n",
    "                prod_LoD.append(relevant_data)\n",
    "\n",
    "#see what first few rows of data look like\n",
    "prod_LoD[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c96c6",
   "metadata": {},
   "source": [
    "## Make dataframes\n",
    "\n",
    "Now we are finally ready to convert both of our LoDs into pandas dataframes which we will download to the repository's data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362aa2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominations</th>\n",
       "      <th>wins</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad-cinderella-535361</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Mar 23, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancin-4051</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Musical</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dancin-535808</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camelot-13313</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camelot-4143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Nov 15, 1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a-life-522289</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barnum-3949</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Musical</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home-3953</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuts-3948</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bent-3823</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Play</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nominations  wins     type          year\n",
       "production                                                     \n",
       "bad-cinderella-535361            0     0  Musical  Mar 23, 2023\n",
       "dancin-4051                      7     2  Musical          1978\n",
       "dancin-535808                    1     0  Musical          2023\n",
       "camelot-13313                    2     0  Musical          1981\n",
       "camelot-4143                     0     0  Musical  Nov 15, 1981\n",
       "...                            ...   ...      ...           ...\n",
       "a-life-522289                    3     0     Play          2020\n",
       "barnum-3949                     10     3  Musical          1980\n",
       "home-3953                        2     0     Play          1980\n",
       "nuts-3948                        1     0     Play          1980\n",
       "bent-3823                        2     0     Play          1980\n",
       "\n",
       "[1552 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tony_data = pd.DataFrame(tony_data_LoD)\n",
    "tony_data = tony_data.set_index('production')\n",
    "tony_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cceb1397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>capacity</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bad-cinderella-535361</th>\n",
       "      <th>May 28, 2023</th>\n",
       "      <td>69</td>\n",
       "      <td>351163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 4, 2023</th>\n",
       "      <td>77</td>\n",
       "      <td>384017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb 19, 2023</th>\n",
       "      <td>100</td>\n",
       "      <td>318478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb 26, 2023</th>\n",
       "      <td>93</td>\n",
       "      <td>684822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar 5, 2023</th>\n",
       "      <td>89</td>\n",
       "      <td>568165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuts-3948</th>\n",
       "      <th>Jul 20, 1980</th>\n",
       "      <td>63</td>\n",
       "      <td>46596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bent-3823</th>\n",
       "      <th>Jun 8, 1980</th>\n",
       "      <td>36</td>\n",
       "      <td>43510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 15, 1980</th>\n",
       "      <td>51</td>\n",
       "      <td>57117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 22, 1980</th>\n",
       "      <td>48</td>\n",
       "      <td>52885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun 29, 1980</th>\n",
       "      <td>57</td>\n",
       "      <td>63754.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    capacity     gross\n",
       "production            date                            \n",
       "bad-cinderella-535361 May 28, 2023        69  351163.0\n",
       "                      Jun 4, 2023         77  384017.0\n",
       "                      Feb 19, 2023       100  318478.0\n",
       "                      Feb 26, 2023        93  684822.0\n",
       "                      Mar 5, 2023         89  568165.0\n",
       "...                                      ...       ...\n",
       "nuts-3948             Jul 20, 1980        63   46596.0\n",
       "bent-3823             Jun 8, 1980         36   43510.0\n",
       "                      Jun 15, 1980        51   57117.0\n",
       "                      Jun 22, 1980        48   52885.0\n",
       "                      Jun 29, 1980        57   63754.0\n",
       "\n",
       "[55318 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_data = pd.DataFrame(prod_LoD)\n",
    "weekly_data = weekly_data.set_index(['production','date'])\n",
    "weekly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a519d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to data folder\n",
    "tony_data.to_csv('data/tony_data.csv')\n",
    "weekly_data.to_csv('data/weekly_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
